cp csv file to s3

create new crawler
point at s3

new tables created in glue catalog table list

athena query editor
can see tables in table list on left
create a sql query and run it

https://docs.aws.amazon.com/athena/latest/ug/connect-to-a-data-source.html
https://aws.amazon.com/blogs/big-data/extracting-and-joining-data-from-multiple-data-sources-with-athena-federated-query/

Serverless Application Repository in your AWS account
search for AthenaJdbcConnector
or AthenaPostgreSQLConnector


secret name - "pg102-secret"
connectionstring - postgres://jdbc:postgres://pg102.cyt4dgtj55oy.us-east-2.rds.amazonaws.com:5432/pg102?user=postgres&password=pg102-secret 
spillbucket
lambdafunctionname
securitygroupids - sg-0ec060f989b5efc55
subnetids - subnet-0808b6c26e6ff6694, subnet-0bf0aafaa5c0521ff

https://aws.amazon.com/blogs/database/joining-historical-data-between-amazon-athena-and-amazon-rds-for-postgresql/


For Application name, keep the default AthenaPostgreSQLConnector.
For CompositeHandler, enter PostGreSqlMuxCompositeHandler.
For SecretNamePrefix, enter AthenaPostgreSQLFederation.
For SpillBucket, enter your S3 bucket name (for this post, historicalbucket).
For ConnectionString, follow the below format postgres://jdbc:postgresql://<RDSEndpoint>:port/<dbname>?user=<username>&password=<password>
For LambdaFunctionName, enter postgresqlathena.
For LambdaMemory and LambdaTimeout, keep the default values.
For SecurityGroupIds, enter the security group ID that is associated to the VPC ID corresponding to your subnet.
For SpillPrefix, create a folder under the S3 bucket you created and specify the name (for this post, athena-spill).
For Subnetids, enter the corresponding subnet that the Lambda function can use to access your data source. For example: subnet1, subnet2.

CREATE EXTERNAL TABLE `s3airport`.`airport` (
ident char(9)
,type char(9)
,name char(9)
,elevation_ft char(9)
,continent  char(9)
,iso_country char(9)
,iso_region char(9)
,municipality char(9)
,gps_code char(9)
,iata_code char(9)
,local_code char(9)
,coordinates char(9)
)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
WITH SERDEPROPERTIES ('field.delim' = ',')
STORED AS INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION 's3://ttsheng-athena/'
TBLPROPERTIES ('classification' = 'csv');

select count(*) from s3airport.airport;
select count(*) from pg102.fly.airport;

select * 
from awsdatacatalog.s3airport.airport s3airport
, pg102.fly.airport pg102airport 
where s3airport.iata_code='CDG' 
and s3airport.iata_code=pg102airport.iata_code;


