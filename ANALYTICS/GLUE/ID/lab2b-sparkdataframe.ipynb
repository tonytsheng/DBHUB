{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {
				"deletable": false,
				"editable": false,
				"trusted": true
			},
			"source": [
				"\n",
				"# Glue Studio Notebook\n",
				"You are now running a **Glue Studio** notebook; before you can start using your notebook you *must* start an interactive session.\n",
				"\n",
				"## Available Magics\n",
				"|          Magic              |   Type       |                                                                        Description                                                                        |\n",
				"|-----------------------------|--------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
				"| %%configure                 |  Dictionary  |  A json-formatted dictionary consisting of all configuration parameters for a session. Each parameter can be specified here or through individual magics. |\n",
				"| %profile                    |  String      |  Specify a profile in your aws configuration to use as the credentials provider.                                                                          |\n",
				"| %iam_role                   |  String      |  Specify an IAM role to execute your session with.                                                                                                        |\n",
				"| %region                     |  String      |  Specify the AWS region in which to initialize a session                                                                                                  |\n",
				"| %session_id                 |  String      |  Returns the session ID for the running session.                                                                                                          |\n",
				"| %connections                |  List        |  Specify a comma separated list of connections to use in the session.                                                                                     |\n",
				"| %additional_python_modules  |  List        |  Comma separated list of pip packages, s3 paths or private pip arguments.                                                                                 |\n",
				"| %extra_py_files             |  List        |  Comma separated list of additional Python files from S3.                                                                                                 |\n",
				"| %extra_jars                 |  List        |  Comma separated list of additional Jars to include in the cluster.                                                                                       |\n",
				"| %number_of_workers          |  Integer     |  The number of workers of a defined worker_type that are allocated when a job runs. worker_type must be set too.                                          |\n",
				"| %worker_type                |  String      |  Standard, G.1X, *or* G.2X. number_of_workers must be set too. Default is G.1X                                                                            |\n",
				"| %glue_version               |  String      |  The version of Glue to be used by this session. Currently, the only valid options are 2.0 and 3.0 (eg: %glue_version 2.0)                                |\n",
				"| %security_config            |  String      |  Define a security configuration to be used with this session.                                                                                            |\n",
				"| %sql                        |  String      |  Run SQL code. All lines after the initial %%sql magic will be passed as part of the SQL code.                                                            |\n",
				"| %streaming                  |  String      |  Changes the session type to Glue Streaming.                                                                                                              |\n",
				"| %etl                        |  String      |   Changes the session type to Glue ETL.                                                                                                                   |\n",
				"| %status                     |              |  Returns the status of the current Glue session including its duration, configuration and executing user / role.                                          |\n",
				"| %stop_session               |              |  Stops the current session.                                                                                                                               |\n",
				"| %list_sessions              |              |  Lists all currently running sessions by name and ID.                                                                                                     |\n",
				"| %spark_conf                 |  String      |  Specify custom spark configurations for your session. E.g. %spark_conf spark.serializer=org.apache.spark.serializer.KryoSerializer                       |"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"editable": true,
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"import sys\n",
				"from awsglue.transforms import *\n",
				"from awsglue.utils import getResolvedOptions\n",
				"from pyspark.context import SparkContext\n",
				"from awsglue.context import GlueContext\n",
				"from awsglue.job import Job\n",
				"  \n",
				"sc = SparkContext.getOrCreate()\n",
				"glueContext = GlueContext(sc)\n",
				"spark = glueContext.spark_session\n",
				"job = Job(glueContext)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"# Retrieve the list of existing buckets\n",
				"\n",
				"import boto3\n",
				"\n",
				"s3 = boto3.client('s3')\n",
				"response = s3.list_buckets()\n",
				"\n",
				"# Output the bucket names\n",
				"print('Existing buckets:')\n",
				"for bucket in response['Buckets']:\n",
				"    print(f'  {bucket[\"Name\"]}')"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"## Read data from Amazon S3 and create DataFrame\n",
				"\n",
				"## Replace the {S3_PATH} below, with your bucket name.\n",
				"\n",
				"s3_path = \"{S3_PATH}\" \n",
				"\n",
				"df = spark.read.load(\"s3://\" + s3_path + \"/input/lab2/sample.csv\", \n",
				"                          format=\"csv\", \n",
				"                          sep=\",\", \n",
				"                          inferSchema=\"true\",\n",
				"                          header=\"true\")\n",
				"\n",
				"## print schema\n",
				"df.printSchema()\n",
				"\n",
				"## show 10 records\n",
				"\n",
				"df.show(10)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"## Write data as Parquert \n",
				"\n",
				"df.write.parquet(\"s3://\" + s3_path + \"/input/lab2/output/parquet/\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"## reading parquet file\n",
				"\n",
				"dfpaquet = spark.read.parquet(\"s3://\" + s3_path + \"/input/lab2/output/parquet/\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"# spark, sparkDFcsv are from the previous example\n",
				"# Print the schema in a tree format\n",
				"\n",
				"dfpaquet.printSchema()\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"## print 5 records\n",
				"\n",
				"dfpaquet.show(5)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"## count the total no. of rows in DataFrame\n",
				"\n",
				"dfpaquet.count()\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"# Select only the \"Country\" column\n",
				"dfpaquet.select('Country')\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"# Select only the \"Country\" column\n",
				"# calling action\n",
				"\n",
				"dfpaquet.select('Country').show()\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"dfpaquet.select('Country').show(10,truncate=False)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"### show multiple columns and create new dataframe\n",
				"\n",
				"dfselect = dfpaquet.select(dfpaquet['Country'], dfpaquet['ItemType'], dfpaquet['SalesChannel'],dfpaquet['TotalRevenue'])\n",
				"\n",
				"dfselect.show(10,truncate=False)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"### Filter by country\n",
				"\n",
				"dfselect.filter(dfpaquet['Country'] == 'United Kingdom').show(10,truncate=False)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"### Filter by country and Total Revenue and create new dataframe\n",
				"\n",
				"dfselectfilter = dfselect.filter((dfpaquet['Country'] == 'United Kingdom') & (dfpaquet['TotalRevenue'] <= 200000.00))\n",
				"\n",
				"dfselectfilter.show(10,truncate=False)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"## perform GroupBy operation \n",
				"\n",
				"dfselectfiltergroupby = dfselectfilter.groupBy(\"ItemType\").sum(\"TotalRevenue\")\n",
				"\n",
				"dfselectfiltergroupby.show(10,truncate=False)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"## perform Order By Operation \n",
				"\n",
				"dfselectfiltergroupbyorderby = dfselectfiltergroupby.orderBy(\"sum(TotalRevenue)\", ascending=False)\n",
				"\n",
				"dfselectfiltergroupbyorderby.show(10,truncate=False)\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Spark createOrReplaceTempView()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"How does the createOrReplaceTempView() method work in Spark and what is it used for? One of the main advantages of Apache Spark is working with SQL along with DataFrame/Dataset API. So if you are comfortable with SQL, you can create a temporary view on DataFrame/Dataset by using createOrReplaceTempView() and using SQL to select and manipulate the data.\n",
				"\n",
				"A Temporary view in Spark is similar to a real SQL table that contains rows and columns but the view is not materialized into files. In this article, we will be discussing what is createOrReplaceTempView() and how to use it to create a temporary view and run Spark SQL queries."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"## converting datafrem to createOrReplaceTempView table\n",
				"\n",
				"dfpaquet.createOrReplaceTempView('dfpaquetsql')"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"spark.sql('select * from dfpaquetsql limit 10').show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"spark.sql('select Country, ItemType , SalesChannel , TotalRevenue from dfpaquetsql limit 10').show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"spark.sql('select ItemType , sum(TotalRevenue) as SumTotalRevenue from dfpaquetsql group by ItemType order by SumTotalRevenue asc limit 10').show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"dfcsvsave = spark.sql('select ItemType , sum(TotalRevenue) as SumTotalRevenue from dfpaquetsql group by ItemType order by SumTotalRevenue asc')"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"## Save as CSV and creating a single file\n",
				"## coalese is very expensive action, it's not recommeneded to use with large dataset\n",
				"\n",
				"singlefile = dfcsvsave.coalesce(1) \n",
				"\n",
				"singlefile.write.format(\"csv\").mode('overwrite').save(\"s3://\" + s3_path + \"/input/lab2/output/csv/\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "plaintext"
				}
			},
			"outputs": [],
			"source": [
				"## stop the current session \n",
				"\n",
				"%stop_session"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "Python_Glue_Session",
			"pygments_lexer": "python3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
