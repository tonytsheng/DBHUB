# bulk import from command line
$ mongoimport --db test --collection inventory \
        --authenticationDatabase admin --username admin --password Pass \
        --drop --file DAT/inventory.crud.json

## import
mongoimport --file=airbnb.new1 --jsonArray --sslCAFile=/home/ec2-user/ssl/global-bundle.pem --verbose --username=docadmin --password=Pass --host=docdb100.cyt4dgtj55oy.us-east-2.docdb.amazonaws.com:27017 --authenticationDatabase=admin --ssl

mongoimport -d tymongo -c test --type csv --file database2.csv --headerline

mongoimport --file=QuickSightDemo_SaasSales.csv --type=csv --headerline --sslCAFile=/home/ec2-user/ssl/global-bundle.pem --verbose --username=docadmin --password=Pass --host=docdb100.cyt4dgtj55oy.us-east-2.docdb.amazonaws.com:27017 --authenticationDatabase=admin --ssl

mongoimport --file=/home/ec2-user/data/airbnb/listings.json  --collection=listings2 --sslCAFile=/home/ec2-user/ssl/global-bundle.pem --verbose --username=docadmin --password=Pass --host=docdb100.cyt4dgtj55oy.us-east-2.docdb.amazonaws.com:27017 --authenticationDatabase=admin --ssl --jsonArray
## make sure input file is just json records:
## no commas, one json doc per row
#{ "item": "journal", "qty": 25, "size": { "h": 14, "w": 21, "uom": "cm" }, "status": "A" }
#{ "item": "notebook", "qty": 50, "size": { "h": 8.5, "w": 11, "uom": "in" }, "status": "A" }
#{ "item": "paper", "qty": 100, "size": { "h": 8.5, "w": 11, "uom": "in" }, "status": "D" }
#
# can also import with --jsonArray
# [{ "item": "journal", "qty": 25, "size": { "h": 14, "w": 21, "uom": "cm" }, "status": "A" },
#{ "item": "notebook", "qty": 50, "size": { "h": 8.5, "w": 11, "uom": "in" }, "status": "A" },
#{ "item": "paper", "qty": 100, "size": { "h": 8.5, "w": 11, "uom": "in" }, "status": "D" } ]

# csv file

# shell commands
mongorestore --username=admin --password=Pass --authenticationDatabase=admin --archive=sampledata.archive 
$ mongo
db.help()

use admin
db.auth("admin","Pass")


use test
rs.status

show databases
show dbs
show collections

db.getName()

s0:PRIMARY> db.adminCommand({listDatabases:1})
{
        "databases" : [
                {
                        "name" : "admin",
                        "sizeOnDisk" : 184320,
                        "empty" : false
                },
                {
                        "name" : "config",
                        "sizeOnDisk" : 77824,
                        "empty" : false
                },
                {
                        "name" : "local",
                        "sizeOnDisk" : 161398784,
                        "empty" : false
                },
                {
                        "name" : "sample_airbnb",
                        "sizeOnDisk" : 55033856,
                        "empty" : false
                },
                {
                        "name" : "sample_analytics",
                        "sizeOnDisk" : 9895936,
                        "empty" : false
                },
                {
                        "name" : "sample_geospatial",
                        "sizeOnDisk" : 987136,
                        "empty" : false
                },
                {
                        "name" : "sample_mflix",
                        "sizeOnDisk" : 41713664,
                        "empty" : false
                },
                {
                        "name" : "sample_restaurants",
                        "sizeOnDisk" : 6164480,
                        "empty" : false
                },
                {
                        "name" : "sample_supplies",
                        "sizeOnDisk" : 983040,
                        "empty" : false
                },
                {
                        "name" : "sample_training",
                        "sizeOnDisk" : 43057152,
                        "empty" : false
                },
                {
                        "name" : "sample_weatherdata",
                        "sizeOnDisk" : 2478080,
                        "empty" : false
                },
                {
                        "name" : "test",
                        "sizeOnDisk" : 11624448,
                        "empty" : false
                }
        ],
        "totalSize" : 333598720,
        "ok" : 1,
        "$clusterTime" : {
                "clusterTime" : Timestamp(1636335796, 1),
                "signature" : {
                        "hash" : BinData(0,"D+VajCvGgeNtWw0hZ9Kfik3GfMI="),
                        "keyId" : NumberLong("7026031798597451780")
                }
        },
        "operationTime" : Timestamp(1636335796, 1)
}

s0:PRIMARY> db.getCollectionNames()
[ "inventory" ]

s0:PRIMARY> db.inventory.find()
{ "_id" : ObjectId("6183e76bb4a0c61187cdd3ce"), "item" : "journal", "qty" : 25, "size" : { "h" : 14, "w" : 21, "uom" : "cm" }, "status" : "A" }
{ "_id" : ObjectId("6183e76bb4a0c61187cdd3cf"), "item" : "paper", "qty" : 100, "size" : { "h" : 8.5, "w" : 11, "uom" : "in" }, "status" : "D" }
{ "_id" : ObjectId("6183e76bb4a0c61187cdd3d0"), "item" : "planner", "qty" : 75, "size" : { "h" : 22.85, "w" : 30, "uom" : "cm" }, "status" : "D" }
{ "_id" : ObjectId("6183e76bb4a0c61187cdd3d1"), "item" : "postcard", "qty" : 45, "size" : { "h" : 10, "w" : 15.25, "uom" : "cm" }, "status" : "A" }
{ "_id" : ObjectId("6183e76bb4a0c61187cdd3d2"), "item" : "notebook", "qty" : 50, "size" : { "h" : 8.5, "w" : 11, "uom" : "in" }, "status" : "A" }

s0:PRIMARY> db.inventory.find( {item: "notebook"})
{ "_id" : ObjectId("6183e76bb4a0c61187cdd3d2"), "item" : "notebook", "qty" : 50, "size" : { "h" : 8.5, "w" : 11, "uom" : "in" }, "status" : "A" }


s0:PRIMARY> db.inventory.find( {item: "postcard"})
{ "_id" : ObjectId("6183e9d3dbc1da23cb031df2"), "item" : "postcard", "qty" : 45, "size" : { "h" : 10, "w" : 15.25, "uom" : "cm" }, "status" : "A" }
{ "_id" : ObjectId("6183e9d3dbc1da23cb031df3"), "item" : "postcard", "qty" : 5, "size" : { "h" : 1, "w" : 15.25, "uom" : "cm" }, "status" : "A" }
{ "_id" : ObjectId("6183e9d3dbc1da23cb031df4"), "item" : "postcard", "qty" : 95, "size" : { "h" : 5, "w" : 15.25, "uom" : "cm" }, "status" : "A" }
{ "_id" : ObjectId("6183e9d3dbc1da23cb031df5"), "item" : "postcard", "qty" : 35, "size" : { "h" : 55, "w" : 15.25, "uom" : "cm" }, "status" : "A" }
{ "_id" : ObjectId("6183e9d3dbc1da23cb031df6"), "item" : "postcard", "qty" : 15, "size" : { "h" : 16, "w" : 15.25, "uom" : "cm" }, "status" : "A" }
{ "_id" : ObjectId("6183e9d3dbc1da23cb031df7"), "item" : "postcard", "qty" : 45, "size" : { "h" : 17, "w" : 15.25, "uom" : "cm" }, "status" : "A" }
{ "_id" : ObjectId("6183e9d3dbc1da23cb031df8"), "item" : "postcard", "qty" : 45, "size" : { "h" : 19, "w" : 15.25, "uom" : "cm" }, "status" : "A" }
{ "_id" : ObjectId("6183e9d3dbc1da23cb031df9"), "item" : "postcard", "qty" : 45, "size" : { "h" : 18, "w" : 15.25, "uom" : "cm" }, "status" : "A" }

s0:PRIMARY> db.listingsAndReviews.find({"property_type":"house"})


s0:PRIMARY> db.createCollection("tonechart")
{
        "ok" : 1,
        "$clusterTime" : {
                "clusterTime" : Timestamp(1636035353, 1),
                "signature" : {
                        "hash" : BinData(0,"OhbhBAms06y8KyBNCuQYXy10Ojg="),
                        "keyId" : NumberLong("7026031798597451780")
                }
        },
        "operationTime" : Timestamp(1636035353, 1)
}
s0:PRIMARY> db.getCollectionNames()
[ "inventory", "tonechart" ]

s0:PRIMARY> db.nfl.count()
866

s0:PRIMARY> db.nfl.find({"title" : {$regex: "BUD"}})

s0:PRIMARY> db.nfl.find({"title" : {$regex: "BUD"}}).count()
99

# find column list - best thing close to desc/explain
s0:PRIMARY> db.listingsAndReviews.findOne()

# or below
# s0:PRIMARY> var col_list=db.listingsAndReviews.findOne();
s0:PRIMARY> for (var col in col_list) {print (col); }
_id
listing_url
name
summary
space
description
neighborhood_overview
notes
transit
access
interaction
house_rules
property_type
room_type
bed_type
minimum_nights
maximum_nights
cancellation_policy
last_scraped
calendar_last_scraped
first_review
last_review
accommodates
bedrooms
beds
number_of_reviews
bathrooms
amenities
price
security_deposit
cleaning_fee
extra_people
guests_included
images
host
address
availability
review_scores
reviews


# query
s0:PRIMARY> db.listingsAndReviews.find({"property_type":"house"}, {"property_type":1, _id:2, "address":3} )
{ "_id" : "6189685e6d8c7bcd4b89d2e7", "property_type" : "house", "address" : "444 Lamont Court, Sunnyside, Georgia, 3839" }
{ "_id" : "6189685e17bcdc2d7a23555c", "property_type" : "house", "address" : "248 Monitor Street, Kula, Arizona, 7851" }
{ "_id" : "6189685e32579ceb69db7d26", "property_type" : "house", "address" : "820 Linwood Street, Brambleton, Palau, 6981" }
{ "_id" : "6187685e17bcdc2d7a23555c", "property_type" : "house", "address" : "248 Monitor Street, Kula, Arizona, 7851" }

# query by type
s0:PRIMARY> db.listingsAndReviews.aggregate( {$sortByCount: "$property_type"} )
{ "_id" : "Apartment", "count" : 3626 }
{ "_id" : "House", "count" : 606 }
{ "_id" : "Condominium", "count" : 399 }
{ "_id" : "Serviced apartment", "count" : 185 }
{ "_id" : "Loft", "count" : 142 }
{ "_id" : "Townhouse", "count" : 108 }
{ "_id" : "Guest suite", "count" : 81 }
{ "_id" : "Bed and breakfast", "count" : 69 }
{ "_id" : "Boutique hotel", "count" : 53 }
{ "_id" : "Guesthouse", "count" : 50 }
{ "_id" : "Hostel", "count" : 34 }
{ "_id" : "Villa", "count" : 32 }
{ "_id" : "Hotel", "count" : 26 }
{ "_id" : "Aparthotel", "count" : 23 }
{ "_id" : "Cottage", "count" : 20 }
{ "_id" : "Other", "count" : 18 }
{ "_id" : "Cabin", "count" : 15 }
{ "_id" : "Bungalow", "count" : 14 }
{ "_id" : "Resort", "count" : 11 }
{ "_id" : "Casa particular (Cuba)", "count" : 9 }

# query by field return only id and country code fields
db.listings2.find({country_code: "USA"}, {item:1, country_code:1 })
db.listings2.find({ country_code: { $in: ["USA", "NL"] }}, {item:1, country_code:1 });

## Cluster connecting
- mongodb://username:password@sample-cluster.cluster-123456789012.us-east-1.docdb.amazonaws.com:27017/?replicaSet=rs0
- mongo shell does not support making connections to a replica set only to individual nodes
- you can code it yourself to figure out what is primary and replicas etc

- python sample call:
client = pymongo.MongoClient('mongodb://%s:%s@docdb100.cluster-cyt4dgtj55oy.us-east-2.docdb.amazonaws.com:27017/?tls=true&tlsCAFile=/home/ec2-user/ssl/global-bundle.pem&replicaSet=rs0&readPreference=secondaryPreferred&retryWrites=false' % (username, pw))

## Failover
# cluster health in python
db_status = db.command({'replSetGetStatus'  :1 })

# output from replSetGetStatus, primary is not up yet
{u'set': u'rs0', u'ok': 1.0, u'myState': 1, 
  u'members': [{u'uptime': 345.0, u'name': u'docdb100.cyt4dgtj55oy.us-east-2.docdb.amazonaws.com:27017', u'self': True, u'state': 1, u'health': 1, u'stateStr': u'PRIMARY', u'_id': 0}], 
  u'date': datetime.datetime(2023, 12, 14, 19, 59, 6), u'operationTime': Timestamp(1702583946, 1)}

# secondary is up too
{u'set': u'rs0', u'ok': 1.0, u'myState': 1, 
  u'members': [{u'uptime': 354.0, u'name': u'docdb100.cyt4dgtj55oy.us-east-2.docdb.amazonaws.com:27017', u'self': True, u'state': 1, u'health': 1, u'stateStr': u'PRIMARY', u'_id': 0}, 
               {u'uptime': 354.0, u'name': u'docdb1002.cyt4dgtj55oy.us-east-2.docdb.amazonaws.com:27017', u'state': 2, u'health': 1, u'stateStr': u'SECONDARY', u'_id': 1}], 
  u'date': datetime.datetime(2023, 12, 14, 19, 59, 15), u'operationTime': Timestamp(1702583955, 1)}

{u'set': u'rs0', u'ok': 1.0, u'myState': 1, 
  u'members': [{u'uptime': 356.0, u'name': u'docdb100.cyt4dgtj55oy.us-east-2.docdb.amazonaws.com:27017', u'self': True, u'state': 1, u'health': 1, u'stateStr': u'PRIMARY', u'_id': 0}, 
               {u'uptime': 356.0, u'name': u'docdb1002.cyt4dgtj55oy.us-east-2.docdb.amazonaws.com:27017', u'state': 2, u'health': 1, u'stateStr': u'SECONDARY', u'_id': 1}], 
  u'date': datetime.datetime(2023, 12, 14, 19, 59, 17), u'operationTime': Timestamp(1702583957, 1)}

# checking member status from CLI
aws docdb describe-db-clusters --db-cluster-identifier docdb100 | jq ' .DBClusters[] | .DBClusterMembers '

#normal status
[
  {
    "DBInstanceIdentifier": "docdb1002",
    "IsClusterWriter": false,
    "DBClusterParameterGroupStatus": "in-sync",
    "PromotionTier": 1
  },
  {
    "DBInstanceIdentifier": "docdb100",
    "IsClusterWriter": true,
    "DBClusterParameterGroupStatus": "in-sync",
    "PromotionTier": 1
  }
]
# CLI failover cluster command
aws docdb failover-db-cluster --db-cluster-identifier docdb100

# when faiover is finished
[
  {
    "DBInstanceIdentifier": "docdb1002",
    "IsClusterWriter": true,
    "DBClusterParameterGroupStatus": "in-sync",
    "PromotionTier": 1
  },
  {
    "DBInstanceIdentifier": "docdb100",
    "IsClusterWriter": false,
    "DBClusterParameterGroupStatus": "in-sync",
    "PromotionTier": 1
  }
]

# output from replSetGetStatus, primary and secondary have switched
{u'set': u'rs0', u'ok': 1.0, u'myState': 1, 
  u'members': [{u'uptime': 107.0, u'name': u'docdb1002.cyt4dgtj55oy.us-east-2.docdb.amazonaws.com:27017', u'self': True, u'state': 1, u'health': 1, u'stateStr': u'PRIMARY', u'_id': 0}, 
               {u'uptime': 107.0, u'name': u'docdb100.cyt4dgtj55oy.us-east-2.docdb.amazonaws.com:27017', u'state': 2, u'health': 1, u'stateStr': u'SECONDARY', u'_id': 1}], 
  u'date': datetime.datetime(2023, 12, 14, 20, 15, 4), u'operationTime': Timestamp(1702584904, 1)}


